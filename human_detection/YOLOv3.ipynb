{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ac0c19",
   "metadata": {},
   "source": [
    "## YOLOv3\n",
    "- download model weights and cfgs at https://pjreddie.com/darknet/yolo/\n",
    "- reference: https://medium.com/@luanaebio/detecting-people-with-yolo-and-opencv-5c1f9bc6a810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69f46f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32a31d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(base_path, image_id, print_size=False):\n",
    "    file_path = '%s/%d.jpg' % (base_path, image_id)\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    if print_size:\n",
    "        print(\"Image %d: %d x %d \" % (image_id, width, height))\n",
    "    \n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02525f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(indices, boxes, classes, image, image_id):\n",
    "    for i in indices:\n",
    "        box = boxes[i[0]]\n",
    "        label = str(classes[0]) \n",
    "        # pt1, pt2, color, thickness\n",
    "        cv2.rectangle(image, \n",
    "                      (round(box[0]), round(box[1])), \n",
    "                      (round(box[0] + box[2]), round(box[1] + box[3])), \n",
    "                      (0, 0, 0), 2)\n",
    "    plt.figure()\n",
    "    plt.title(\"Image %d\" % image_id)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "036ed99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_box(classes, image, image_id, width, height, output, \n",
    "                        conf_threshold=0.1, plot=True):\n",
    "    \"\"\"\n",
    "    # only filter the box with high confidence to classified as person (class_id=0)\n",
    "    \"\"\"\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    area, pct_area = 0, 0\n",
    "\n",
    "    for out in output:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "    \n",
    "            if class_id == 0:\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > conf_threshold:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    area += (w * h)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "    \n",
    "    if plot:\n",
    "        plot_image(indices, boxes, classes, image, image_id)\n",
    "    \n",
    "    if area > 0:\n",
    "        area /= len(boxes)\n",
    "        pct_area = area / (width * height)\n",
    "    \n",
    "    return confidences, boxes, pct_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd760ff",
   "metadata": {},
   "source": [
    "## Detection criteria\n",
    "- Hyperparameters to classify the image contains human\n",
    "    - confidence threshold of bounding box: 0.2\n",
    "    - The area of bounding box occupies more than 5% of the image\n",
    "\n",
    "## YOLO Performance on 100 images\n",
    "- YOLOv3-320: Accuracy: 89%. Total time used: 1 min. Same performance of yolov3-320 and yolov3-608.\n",
    "- Fail reasons\n",
    "    - Classify clothing as person: Image 132, 143, 163, 260, 289, 309, 311, 320\n",
    "    - Human figure is too small: Image 24\n",
    "    - The part of human body is amplified: Image 688\n",
    "    - Most of the human body is covered by cloths: Image 283\n",
    "- **Pros**\n",
    "    - Fast and efficient. Easy to control hyperparameters. No need to consume disk space.\n",
    "- **Cons**\n",
    "    - YOLO cannot distinguish clothing from human when the shape is very similar, which is commonly seen in clothing product images.\n",
    "\n",
    "## Comparison with human parsing\n",
    "- YOLO performs better than human parsing at cases when most of the human body is covered by cloths.\n",
    "- Human parsing performs better when YOLO wrongly classifies clothes into person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c0d08819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load COCO class names\n",
    "classes = None\n",
    "with open('../../YOLOv3_model/coco.names.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# use YOLOv3-320 pre-trained model\n",
    "net = cv2.dnn.readNet('../../YOLOv3_model/yolov3-320.weights', '../../YOLOv3_model/yolov3-320.cfg')\n",
    "\n",
    "# get image_ids\n",
    "images_ids = [int(x.split(\"/\")[-1].split(\".\")[0]) for x in glob.glob('../../HKTVMall_data/*.jpg')]\n",
    "images_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "765fa69b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0\n",
      "The image does not contain person \n",
      "\n",
      "Image 1\n",
      "The image does not contain person \n",
      "\n",
      "Image 2\n",
      "Average confidence is 64.61%\n",
      "62.17% of the image is classified as person \n",
      "\n",
      "Image 3\n",
      "Average confidence is 34.46%\n",
      "61.74% of the image is classified as person \n",
      "\n",
      "Image 5\n",
      "Average confidence is 73.44%\n",
      "70.04% of the image is classified as person \n",
      "\n",
      "Image 6\n",
      "Average confidence is 90.41%\n",
      "84.40% of the image is classified as person \n",
      "\n",
      "Image 7\n",
      "Average confidence is 71.95%\n",
      "84.50% of the image is classified as person \n",
      "\n",
      "Image 10\n",
      "The image does not contain person \n",
      "\n",
      "Image 16\n",
      "The image does not contain person \n",
      "\n",
      "Image 21\n",
      "Average confidence is 70.35%\n",
      "56.85% of the image is classified as person \n",
      "\n",
      "Image 23\n",
      "Average confidence is 53.83%\n",
      "10.40% of the image is classified as person \n",
      "\n",
      "Image 24\n",
      "The image does not contain person \n",
      "\n",
      "Image 30\n",
      "The image does not contain person \n",
      "\n",
      "Image 31\n",
      "The image does not contain person \n",
      "\n",
      "Image 40\n",
      "Average confidence is 72.72%\n",
      "69.68% of the image is classified as person \n",
      "\n",
      "Image 43\n",
      "Average confidence is 83.88%\n",
      "63.64% of the image is classified as person \n",
      "\n",
      "Image 44\n",
      "Average confidence is 74.14%\n",
      "75.63% of the image is classified as person \n",
      "\n",
      "Image 45\n",
      "Average confidence is 71.67%\n",
      "76.21% of the image is classified as person \n",
      "\n",
      "Image 46\n",
      "Average confidence is 87.10%\n",
      "77.23% of the image is classified as person \n",
      "\n",
      "Image 47\n",
      "The image does not contain person \n",
      "\n",
      "Image 48\n",
      "The image does not contain person \n",
      "\n",
      "Image 49\n",
      "Average confidence is 83.10%\n",
      "73.65% of the image is classified as person \n",
      "\n",
      "Image 51\n",
      "Average confidence is 84.81%\n",
      "77.26% of the image is classified as person \n",
      "\n",
      "Image 53\n",
      "Average confidence is 78.40%\n",
      "76.75% of the image is classified as person \n",
      "\n",
      "Image 55\n",
      "The image does not contain person \n",
      "\n",
      "Image 56\n",
      "The image does not contain person \n",
      "\n",
      "Image 60\n",
      "The image does not contain person \n",
      "\n",
      "Image 63\n",
      "The image does not contain person \n",
      "\n",
      "Image 73\n",
      "Average confidence is 79.93%\n",
      "29.04% of the image is classified as person \n",
      "\n",
      "Image 74\n",
      "Average confidence is 27.90%\n",
      "40.34% of the image is classified as person \n",
      "\n",
      "Image 83\n",
      "Average confidence is 27.90%\n",
      "40.34% of the image is classified as person \n",
      "\n",
      "Image 84\n",
      "Average confidence is 75.94%\n",
      "74.98% of the image is classified as person \n",
      "\n",
      "Image 85\n",
      "Average confidence is 77.08%\n",
      "31.69% of the image is classified as person \n",
      "\n",
      "Image 86\n",
      "Average confidence is 72.90%\n",
      "78.88% of the image is classified as person \n",
      "\n",
      "Image 87\n",
      "Average confidence is 69.89%\n",
      "63.31% of the image is classified as person \n",
      "\n",
      "Image 89\n",
      "Average confidence is 72.96%\n",
      "54.72% of the image is classified as person \n",
      "\n",
      "Image 92\n",
      "Average confidence is 35.21%\n",
      "7.33% of the image is classified as person \n",
      "\n",
      "Image 93\n",
      "The image does not contain person \n",
      "\n",
      "Image 94\n",
      "The image does not contain person \n",
      "\n",
      "Image 96\n",
      "Average confidence is 54.54%\n",
      "81.67% of the image is classified as person \n",
      "\n",
      "Image 102\n",
      "The image does not contain person \n",
      "\n",
      "Image 108\n",
      "The image does not contain person \n",
      "\n",
      "Image 109\n",
      "The image does not contain person \n",
      "\n",
      "Image 110\n",
      "The image does not contain person \n",
      "\n",
      "Image 112\n",
      "Average confidence is 37.53%\n",
      "77.89% of the image is classified as person \n",
      "\n",
      "Image 121\n",
      "The image does not contain person \n",
      "\n",
      "Image 131\n",
      "Average confidence is 77.48%\n",
      "59.42% of the image is classified as person \n",
      "\n",
      "Image 132\n",
      "Average confidence is 36.73%\n",
      "75.86% of the image is classified as person \n",
      "\n",
      "Image 141\n",
      "Average confidence is 83.50%\n",
      "38.61% of the image is classified as person \n",
      "\n",
      "Image 143\n",
      "Average confidence is 42.10%\n",
      "46.17% of the image is classified as person \n",
      "\n",
      "Image 144\n",
      "Average confidence is 65.41%\n",
      "22.97% of the image is classified as person \n",
      "\n",
      "Image 151\n",
      "Average confidence is 64.11%\n",
      "36.36% of the image is classified as person \n",
      "\n",
      "Image 152\n",
      "Average confidence is 79.17%\n",
      "57.14% of the image is classified as person \n",
      "\n",
      "Image 163\n",
      "Average confidence is 84.82%\n",
      "27.83% of the image is classified as person \n",
      "\n",
      "Image 167\n",
      "The image does not contain person \n",
      "\n",
      "Image 168\n",
      "Average confidence is 96.01%\n",
      "58.58% of the image is classified as person \n",
      "\n",
      "Image 181\n",
      "The image does not contain person \n",
      "\n",
      "Image 185\n",
      "Average confidence is 90.13%\n",
      "26.61% of the image is classified as person \n",
      "\n",
      "Image 203\n",
      "Average confidence is 78.99%\n",
      "38.48% of the image is classified as person \n",
      "\n",
      "Image 204\n",
      "The image does not contain person \n",
      "\n",
      "Image 217\n",
      "The image does not contain person \n",
      "\n",
      "Image 230\n",
      "Average confidence is 84.84%\n",
      "51.85% of the image is classified as person \n",
      "\n",
      "Image 238\n",
      "The image does not contain person \n",
      "\n",
      "Image 242\n",
      "The image does not contain person \n",
      "\n",
      "Image 251\n",
      "Average confidence is 71.55%\n",
      "58.46% of the image is classified as person \n",
      "\n",
      "Image 254\n",
      "Average confidence is 68.06%\n",
      "43.89% of the image is classified as person \n",
      "\n",
      "Image 255\n",
      "The image does not contain person \n",
      "\n",
      "Image 256\n",
      "Average confidence is 67.13%\n",
      "36.66% of the image is classified as person \n",
      "\n",
      "Image 258\n",
      "Average confidence is 72.61%\n",
      "19.64% of the image is classified as person \n",
      "\n",
      "Image 260\n",
      "Average confidence is 52.68%\n",
      "21.11% of the image is classified as person \n",
      "\n",
      "Image 271\n",
      "Average confidence is 75.67%\n",
      "55.72% of the image is classified as person \n",
      "\n",
      "Image 277\n",
      "Average confidence is 70.63%\n",
      "59.86% of the image is classified as person \n",
      "\n",
      "Image 283\n",
      "The image does not contain person \n",
      "\n",
      "Image 286\n",
      "The image does not contain person \n",
      "\n",
      "Image 289\n",
      "Average confidence is 57.46%\n",
      "50.93% of the image is classified as person \n",
      "\n",
      "Image 295\n",
      "Average confidence is 69.91%\n",
      "53.38% of the image is classified as person \n",
      "\n",
      "Image 298\n",
      "Average confidence is 80.15%\n",
      "64.10% of the image is classified as person \n",
      "\n",
      "Image 300\n",
      "The image does not contain person \n",
      "\n",
      "Image 308\n",
      "Average confidence is 85.36%\n",
      "62.31% of the image is classified as person \n",
      "\n",
      "Image 309\n",
      "Average confidence is 76.38%\n",
      "81.06% of the image is classified as person \n",
      "\n",
      "Image 311\n",
      "Average confidence is 77.95%\n",
      "67.37% of the image is classified as person \n",
      "\n",
      "Image 320\n",
      "Average confidence is 84.89%\n",
      "70.94% of the image is classified as person \n",
      "\n",
      "Image 325\n",
      "The image does not contain person \n",
      "\n",
      "Image 337\n",
      "The image does not contain person \n",
      "\n",
      "Image 342\n",
      "Average confidence is 62.02%\n",
      "70.48% of the image is classified as person \n",
      "\n",
      "Image 344\n",
      "Average confidence is 78.39%\n",
      "56.88% of the image is classified as person \n",
      "\n",
      "Image 349\n",
      "The image does not contain person \n",
      "\n",
      "Image 351\n",
      "The image does not contain person \n",
      "\n",
      "Image 361\n",
      "Average confidence is 64.64%\n",
      "42.72% of the image is classified as person \n",
      "\n",
      "Image 365\n",
      "The image does not contain person \n",
      "\n",
      "Image 370\n",
      "The image does not contain person \n",
      "\n",
      "Image 443\n",
      "Average confidence is 43.39%\n",
      "50.59% of the image is classified as person \n",
      "\n",
      "Image 484\n",
      "Average confidence is 62.12%\n",
      "26.78% of the image is classified as person \n",
      "\n",
      "Image 487\n",
      "Average confidence is 90.49%\n",
      "25.20% of the image is classified as person \n",
      "\n",
      "Image 497\n",
      "The image does not contain person \n",
      "\n",
      "Image 633\n",
      "Average confidence is 76.12%\n",
      "49.42% of the image is classified as person \n",
      "\n",
      "Image 688\n",
      "The image does not contain person \n",
      "\n",
      "Image 721\n",
      "The image does not contain person \n",
      "\n",
      "Image 742\n",
      "The image does not contain person \n",
      "\n",
      "Image 757\n",
      "Average confidence is 52.18%\n",
      "35.60% of the image is classified as person \n",
      "\n",
      "Total time used: 51.1810\n"
     ]
    }
   ],
   "source": [
    "result_dict = {\"image_id\": [], \"confidence\": [], \"box_area\": [], \"yolo_pred\": []}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for image_id in images_ids:\n",
    "    result_dict[\"image_id\"].append(image_id)\n",
    "    image, w, h = read_image('../../HKTVMall_data', image_id, print_size=False)\n",
    "\n",
    "    net.setInput(cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
    "\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    confs, boxes, pct_area = create_bounding_box(classes, image, image_id, w, h, outs, \n",
    "                                                 conf_threshold=0.2, plot=False)\n",
    "    print(\"Image %d\" % image_id)\n",
    "    if len(confs) == 0 or pct_area < 0.05:\n",
    "        print(\"The image does not contain person \\n\")\n",
    "        result_dict[\"confidence\"].append(0)\n",
    "        result_dict[\"box_area\"].append(0)\n",
    "        result_dict[\"yolo_pred\"].append(0)\n",
    "    else:\n",
    "        print(\"Average confidence is {:0.2%}\".format(np.mean(confs)))\n",
    "        print(\"{:0.2%} of the image is classified as person \\n\".format(pct_area))\n",
    "        result_dict[\"confidence\"].append(round(np.mean(confs), 4))\n",
    "        result_dict[\"box_area\"].append(round(pct_area, 4))\n",
    "        result_dict[\"yolo_pred\"].append(1)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total time used: %.4f\" % (end - start))\n",
    "    \n",
    "result_df = pd.DataFrame.from_dict(result_dict, orient=\"columns\")\n",
    "result_df = result_df.sort_values(\"image_id\")\n",
    "result_df.to_csv(\"yolo_320_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c8f4b",
   "metadata": {},
   "source": [
    "### Comparison with human parsing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0562ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_res = pd.read_csv(\"yolo_320_result.csv\")\n",
    "par_res = pd.read_csv(\"human_parsing_result.csv\")\n",
    "label = pd.read_csv(\"true_label.csv\")\n",
    "\n",
    "res = yolo_res.merge(par_res, on=\"image_id\")\\\n",
    "              .merge(label, on=\"image_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20103fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo accuracy: 89.00%\n",
      "human parsing accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "yolo_acc = np.mean(res[\"yolo_pred\"] == res[\"y_true\"])\n",
    "pars_acc = np.mean(res[\"par_pred\"] == res[\"y_true\"])\n",
    "\n",
    "print(\"yolo accuracy: {:.2%}\".format(yolo_acc))\n",
    "print(\"human parsing accuracy: {:.2%}\".format(pars_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbae0b",
   "metadata": {},
   "source": [
    "- Human parsing performs better when YOLO wrongly classifies clothes into person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dd801941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>yolo_pred</th>\n",
       "      <th>par_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>132</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>143</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>163</td>\n",
       "      <td>0.8482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>260</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>283</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>289</td>\n",
       "      <td>0.5746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>309</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>311</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>320</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>688</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id  confidence  yolo_pred  par_pred  y_true\n",
       "11        24      0.0000          0         0       1\n",
       "47       132      0.3673          1         0       0\n",
       "49       143      0.4210          1         0       0\n",
       "53       163      0.8482          1         0       0\n",
       "69       260      0.5268          1         0       0\n",
       "72       283      0.0000          0         0       1\n",
       "74       289      0.5746          1         0       0\n",
       "79       309      0.7638          1         0       0\n",
       "80       311      0.7795          1         0       0\n",
       "81       320      0.8489          1         0       0\n",
       "96       688      0.0000          0         1       1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res[\"yolo_pred\"] != res[\"y_true\"]][[\"image_id\", \"confidence\",\"yolo_pred\", \"par_pred\", \"y_true\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7863848",
   "metadata": {},
   "source": [
    "- YOLO performs better than human parsing at cases when most of the human body is covered by cloths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6a87429e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>yolo_pred</th>\n",
       "      <th>pct_pixel</th>\n",
       "      <th>par_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>757</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id  yolo_pred  pct_pixel  par_pred  y_true\n",
       "10        23          1     0.0390         0       1\n",
       "11        24          0     0.0405         0       1\n",
       "28        73          1     0.0472         0       1\n",
       "32        85          1     0.0400         0       1\n",
       "39        96          1     0.0332         0       1\n",
       "40       102          0     0.2926         1       0\n",
       "48       141          1     0.0032         0       1\n",
       "50       144          1     0.0168         0       1\n",
       "51       151          1     0.0188         0       1\n",
       "57       185          1     0.0147         0       1\n",
       "58       203          1     0.0265         0       1\n",
       "64       251          1     0.0433         0       1\n",
       "68       258          1     0.0370         0       1\n",
       "72       283          0     0.0401         0       1\n",
       "99       757          1     0.0353         0       1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res[\"par_pred\"] != res[\"y_true\"]][[\"image_id\", \"yolo_pred\", \"pct_pixel\", \"par_pred\", \"y_true\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20509a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.10",
   "language": "python",
   "name": "pytorch1.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
